# Tokenization in LLMs

Large language models (LLMs) are just a very complex mathematical model which takes in a bunch of numbers and outputs a processed bunch of numbers. To make sense of these numbers and get the desired result, we must associate some meaning to these numbers and while we train the models, we try to make it output those bunch of numbers whose associated meaning makes sense.
